{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This programming assignment has several sections for each part you should fill out wihtin this one jupyter notebook. I suggest \"saving as\" a new filename so if you accidentally delete some of the instructions while editing you can recover easily.   However, if you have accidently mucked up these instructions you can also \"rename\" the file and when you reload the jupyter hub it will automatically restore any missing files from the online repository. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubric \n",
    "\n",
    "| **PS4016 Assignment 1 Rubric** | **Markdown/Narrative Content**                                                                                                                                       | **Code Comment**                                                 | **Code Content**                                                                                                                   |\n",
    "| ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1st**           | Coherent and complete description of motivating questions,  rationale for analysis, and correct description of conclusions to be drawn from resulting data analysis. | Code comments are present and correct for all non-trivial code.  | Complete, working and correct code in all parts assignment.                                                                        |\n",
    "| **2.1**           | Coherent explanations of most parts project with minor errors and/or missing key/important details.                                                                  | Code comments or sometimes missing and/or contain minor errors.  | Code executes without errors (warnings OK) but in some cases produces unexpected/incorrect results.                                |\n",
    "| **2.2**           | Partially incoherent/unclear answer with occasional substantive errors in understanding.                                                                             | Code comments mostly missing with occasional substantive errors. | Code does not execute and fails with errors, but code would take minor revision to correct.                                        |\n",
    "| **3rd**           | Unclear/uncoherent answer that addresses only a minoirty of the assignment                                                                                           | Code comments not present.                                       | Code does not execute and would take major revisions to correct, multiple substantive errors and/or mostly irrelevant information. |\n",
    "| **Fail**          | No narrative descriptions present                                                                                                                                    |                                                                  | Non-executing code, completely incorrect and/or irrelevant to question.                                                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid in Scotland\n",
    "\n",
    "This is a mini real world data analysis.  There is lots of open data available from various sources. I've done a little bit of preprocessing of the data to make it easier for this assignment, but it is all real data downloaded from public datasets.  In this excercise I want you to take real public data about COVID cases in Scotland and combine it with demographic information in order to derive some insights about the distribution of COVID cases in scotland.   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tasks\n",
    "\n",
    "### For each task you need to do: \n",
    "\n",
    "A) Write code to generate the output\n",
    "\n",
    "B) Include written description of your code.  This should be written inline with the code using a # to indicate a comment line.  Something like the following: \n",
    "\n",
    "```python\n",
    "#Get cases/100k by dividing cases by the population to get per capita rate and multipy by 100,000\n",
    "result = 100000*(cases/population)\n",
    "```\n",
    "\n",
    "C) Finish with a markdown cell that explains what the output shows and how you can interpret this output.  What, if anything, does the analysis reveal? Is there an interesting pattern in the data, or nothing useful? \n",
    "\n",
    "### *** BE SURE TO INCLUDE A and B and C in each numbered task below *** \n",
    "\n",
    "### List of tasks:\n",
    "1) A table of the Scottish Councils for overall total covid cases per 100,000 population summed over the entire time perioud of your dataset.  Include in the table:  Council Name, the total cases/100k, total population in the council, and population density in people per Hectare.\n",
    "\n",
    "2) A table of the top 10 Scottish Intermediate Zones for cumulative total covid cases per 100,000 population. Which includes the IZ Name, Council Name, the total cases/100k, the student population percentage, the level of deprivation as indexed by SIMD. \n",
    "\n",
    "3) A table of the top 10 Scottish Intermediate Zones which had the highest single week incidences of covid cases per 100,000 population. Which includes the intermediate zone name, council name, the covid incidence in cases/100k, the date this peak incidence occured, the student population percentage, the level of deprivation as indexed by SIMD.\n",
    "\n",
    "\n",
    "4) Graph the cases/100k over time for the Intermediate Zone with the peak weekly incidence you identified above. Note: We haven't covered how to handle dates.  So I created two options a column \"Days from 2020-03-01\" in the dataset, and a \"datetime\" object column \"Date\". I suggest uing the \"Days from 2020-03-01\" column as it's easy to think about and calculate because it's just an integer number of days, it makes an easy X-axis. In order to make the graph(s) you will need to make a dataframe with appropriate columns. Make sure you calculate the values explicitly and correctly. \n",
    "\n",
    "6) Depravation has been suggested as an factor in COVID.  Graph cases/100k over time seperating into the 5 SIMD quintiles.  \n",
    "\n",
    "5) Pupils and students were often mentioned in news coverage of covid. Graph cases/100k overtime seperating intermediate zones with students making up 20% or more of the population and zones with less than 20% of the population being students.  \n",
    "\n",
    "6)  The Welly Ball.  In 2021 there was a report that a charity ball at St Andrews was the cause of a spike in cases. See: https://www.thecourier.co.uk/fp/news/fife/2734368/charity-ball-linked-to-spike-in-covid-cases-at-st-andrews-university/  Can you provide some data analysis that would help support or refute this claim?   For this task I'm not giving you an explicit output to create. Use your judgement to create an analysis. \n",
    "You might want to know which of the intermediate zones are in St Andrews.  You can find an interactive map of the intermediate zones in Fife here: \n",
    "https://statistics.gov.scot/atlas/resource?uri=http%3A%2F%2Fstatistics.gov.scot%2Fid%2Fstatistical-geography%2FS12000047\n",
    "\n",
    "\n",
    "\n",
    "**NOTE** When you have that you can use whatever way to make the graph you want. Depending on how you structure you dataframes different ways work easier than others. Likely the simplest is the easy pandas plot function.  That's fine.  Another option is to utilize the seaborn lineplot function in the dataset and use the following function (substiting the appropriate values in the inputs for the variable containing your data and the columns names you want to plot): \n",
    "```\n",
    "sns.lineplot(data=DATAFRAMENAME,x=COLUMN_NAME,y=COLUMN_NAME,hue=COLUMN_NAME)\n",
    "```\n",
    "However, beware that it's easy to make plots you don't intend. Be sure to calculate correcly and organize your data clearly so you know what to plot.  \n",
    "\n",
    "It also may be useful and easier to understand if convert from days from 2020-3-01 to weeks from 2020-3-01.  Just divide days by 7 to get this into weeks (because there are 7 days per week).\n",
    "\n",
    "### Note:\n",
    "\n",
    "You will need to create some derived outcome measures and combine data to effectively do these tasks.  You'll need to calculate population density and student population percentage, and covid incidence. You may also need other derived columns depending on your strategy for creating the outputs. \n",
    "The covid incidence might be new to you.  There are various ways to look at covid outcomes. A common metric used is cases per 100,000 population. This normalizes by population so it's not always areas with bigger populations that are higher (8,000 cases in St Andrews is very different to 8,000 cases in London).  To get this value you calculate case per person and then multiply by 100,000. This can be calculated with the following formula.\n",
    "\n",
    "```\n",
    "result = 100000*(cases/population)\n",
    "```\n",
    "\n",
    "## Covid Data\n",
    "The COVID data comes from Public Health Scotland: https://www.publichealthscotland.scot/our-areas-of-work/covid-19/covid-19-data-and-intelligence/covid-19-daily-cases-in-scotland-dashboard/overview-of-the-daily-covid-19-data-dashboard/\n",
    "\n",
    "The COVID data is the file: scotland_covid_by_IZ.csv\n",
    "\n",
    "I have done various things to make the dataset a bit easier to handle.  I've reduced the data to providing just 1 value per week instead of every day. I've also created some extra columns for ease of use.   \n",
    "\n",
    "The covid data includes (among others) the following columns that you should find useful:\n",
    "\n",
    "| Column Name| Description|\n",
    "|-----------|-------------|\n",
    "| Date| Data string YYYYMMDD|\n",
    "|IntZone|The unique ID code for the intermediate zone the data comes from **USE FOR GROUPING**|\n",
    "|CA| Code indentifying the council area|\n",
    "|Positive7Day|  Number of postive cases in the preceding 7 days|\n",
    "|Days from 2020-03-01| Number of days from March 1st, 2020, use for plotting|\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "## Demographic Data\n",
    "The demographic data about student populations comes from the Scotland 2011 census table #QS102SC. I preprocessed the raw data to provide an easier analysis for this assignment.   The census data is given in terms of \"Data Zones\" which are small areas of about 500-1000 people.  But because COVID status is potentially sensitive information in order to protect privacy COVID data is released at the \"Intermediate Zone\" (IZ) level.  These are groups of about about 5 data zones.  So when using this data it is needed to aggregagate the demographic datazones into intermediate zone level to be able to combine the demographic information with the covid dataset.  **I have done this for you already.**\n",
    "\n",
    "### student numbers \n",
    "The student population data is in the file: studentPop_by_IZ.csv\n",
    "\n",
    "| Column Name| Description|\n",
    "|-----------|-------------|\n",
    "|InterZone|The intermediate zone unique ID|\n",
    "|studentPop|Number of students in the zone|\n",
    "\n",
    "\n",
    "### SIMD and Population\n",
    "The Scottish Index of Multiple Deprivation (SIMD) is the method Scotland uses to quantify Socie-Economic Status of local areas of scotland. More information can be found from the the Scottish Government website [link](https://www.gov.scot/collections/scottish-index-of-multiple-deprivation-2020/).  \n",
    "Commonly SIMD is grouped into 5 \"quintiles\" from 1(most deprived) to 5 (least deprived) at a level of postcodes.  There is no direct equivalent for intermediate zones. There are various ways to quantify the SIMD of the intermediate zones (IZ).  I've provided a a version for you that looks at the population within an IZ and classifies it by the largest SIMD quintile by population. \n",
    "\n",
    "The SIMD data is in the file: scotland_simd_by_IZ.csv\n",
    "\n",
    "| Column Name| Description|\n",
    "|-----------|-------------|\n",
    "|InterZone|The intermediate zone unique ID|\n",
    "|Population| The population for the intermediate zone, \n",
    "|Area (hectares)| The area of the zone in hectares|\n",
    "|simd_mode| The simd quintile with the largest population in the IZ|\n",
    "\n",
    "\n",
    "## Mapping datasets\n",
    "\n",
    "\n",
    "Intermediate zones are all given a unique alphanumeric code.  Here is a mapping that goes from the code to a common name for the neighboorhood.  Names are not unique, there are several different cities/councils that have common neighboorhood names. So whenever you use a IZ name you also have to specifie council to identify the correct one. \n",
    "\n",
    "IZ mapping is in intermediate_zone_names_codes.csv\n",
    "\n",
    "| Column Name| Description|\n",
    "|-----------|-------------|\n",
    "|IntZoneCode|The intermediate zone unique ID|\n",
    "|IntZoneName|A string giving the common name of the Intermediate Zone \n",
    "\n",
    "Similarly the councils have codes and names as well.  \n",
    "\n",
    "The council code mapping is in: council_area_names_codes.csv\n",
    "\n",
    "| Column Name| Description|\n",
    "|-----------|-------------|\n",
    "|CACode |The council unique ID|\n",
    "|CAName| A string giving the name of the council Zone |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read in the covid case data from the files. \n",
    "covidData = pd.read_csv('scotland_covid_weekly_by_IZ_for_assignment.csv')\n",
    "\n",
    "#Convert the date column to a datetime object.  This is special datatype\n",
    "#that allows for easy manipulation of dates.   It is always needed when working with dates.\n",
    "#The format string tells pandas how to interpret the date.  %Y is the year, %m is the month, and %d is the day.\n",
    "#I still suggest you use the 'Days from 2020-01-01' column.  as it's easier to work with.  \n",
    "# It's just harder to work out the actual date. You can use this date column as well if you want to.\n",
    "covidData['Date']=pd.to_datetime(covidData['Date'], format='%Y%m%d')\n",
    "\n",
    "#read in the demographic data\n",
    "simdData = pd.read_csv('scotland_demographic_by_IZ_for_assignment.csv')\n",
    "\n",
    "#read in the student population data\n",
    "studentPop = pd.read_csv('studentPop_by_IZ.csv')\n",
    "\n",
    "#Read in the IZ name mapping data\n",
    "izNames = pd.read_csv('intermediate_zone_names_codes.csv')\n",
    "\n",
    "#Read in the council code name mapping data\n",
    "councilNames = pd.read_csv('council_area_names_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jmaPy38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
